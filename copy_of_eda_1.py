# -*- coding: utf-8 -*-
"""Copy of EDA-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SacBsfMBBBEaQYdg0VTD49w4ycpbM_is

# Prerequisites
Install the required libraries:
1. pandas: `pip install pandas`
2. numpy: `pip install numpy`
3. matplotlib: `pip install matplotlib`
4. seaborn: `pip install seaborn`
5. plotly: `pip install plotly`
6. sklearn: `pip install scikit-learn`
7. xgboose: `pip install xgboost`
"""
from flask import Flask, jsonify

app = Flask(__name__)


# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objs as go

import warnings
warnings.simplefilter('ignore')
# %matplotlib inline

df = pd.read_csv('210619monatszahlenjuni2021monatszahlen2106verkehrsunfaelle.csv')

df.head(20)

df.isna().sum()

df.drop(['VORJAHRESWERT', 'VERAEND_VORMONAT_PROZENT', 'VERAEND_VORJAHRESMONAT_PROZENT','ZWOELF_MONATE_MITTELWERT'], axis=1, inplace=True)
df.columns = ['Category', 'Accident Type', 'Year', 'Month', 'Value']

df

df.isna().sum()

df.isna().sum()

test = df[df['Year'] == 2021]
df = df[~(df['Month']=='Summe')]
df = df[~(df['Year'] == 2021)]

df.info()

df['Month'] = df['Month'].apply(lambda x: int(x[::-1][0:2][::-1]))

df

df['Month'].value_counts()

df['Year'].unique()

df = df[~((df['Category']=='Alkoholunf√§lle')&(df['Accident Type']=='insgesamt')&(df['Year']==2021))]

df.reset_index(inplace=True, drop=True)

"""## What are the different Categories of Accidents?"""

plt.figure(figsize=(15, 6))
fig1 = px.histogram(
    data_frame=df,
    x = 'Category',
    title='Distribution of various Categories'
)
# figsend1 = go.histogram(
#     data_frame=df,
#     x = 'Category',
#     title='Distribution of various Categories'
# )
# fig.show()

"""The data seems to be overall balanced.

### What are the various Accident Types?
"""

plt.figure(figsize=(15, 6))
fig2 = px.histogram(
    data_frame=df,
    x = 'Accident Type',
    title='Distribution of Different Types of Accidents'
)
# figsend2 = go.histogram(
#     data_frame=df,
#     x = 'Accident Type',
#     title='Distribution of Different Types of Accidents'
# )
# fig.show()

"""This does not seem to a balanced type.

### Accidents year wise?
"""

df

year_wise = df.groupby('Year').sum()['Value']

year_wise = pd.DataFrame(year_wise)

year_wise.reset_index(inplace=True)

year_wise

fig3 = px.bar(
    data_frame=year_wise,
    x = 'Year',
    y = 'Value',
    title='Year Wise Accident Distribution'
)
# fig.show()

"""### Month wise?"""

month_wise = df.groupby('Month').sum()['Value']

month_wise = pd.DataFrame(month_wise)
month_wise.reset_index(inplace=True)
month_wise

fig4 = px.bar(
    data_frame=month_wise,
    x = 'Month',
    y = 'Value',
    title='Month Wise Accident Distribution'
)

# fig.show()

"""### Category wise?"""

category_wise = df.groupby('Category').sum()['Value']
category_wise = pd.DataFrame(category_wise)
category_wise.reset_index(inplace=True)
category_wise

fig5 = px.bar(
    data_frame=category_wise,
    x = 'Category',
    y = 'Value',
    title='Category Wise Accident Distribution'
)
# fig.show()

"""### Accident Type wise"""

accident_wise = df.groupby('Accident Type').sum()['Value']
accident_wise = pd.DataFrame(accident_wise)
accident_wise.reset_index(inplace=True)
accident_wise

fig6 = px.bar(
    data_frame=accident_wise,
    x = 'Accident Type',
    y = 'Value',
    title='Type Wise Accident Distribution'
)
# fig.show()

"""### ML Model"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def evaluate(model, X_train, y_train, X_test, y_test):
    print('TRAIN')
    pred = model.predict(X_train)
    print(f'MEAN ABSOLUTE ERROR: {mean_absolute_error(y_train, pred)}')
    print(f'MEAN SQUARED ERROR: {mean_squared_error(y_train, pred)}')
    print(f'ROOT MEAN SQUARED ERROR: {np.sqrt(mean_squared_error(y_train, pred))}')
    print(f'R2 SCORE: {r2_score(y_train, pred)}')
    print('###############################')
    print('TEST')
    pred = model.predict(X_test)
    print(f'MEAN ABSOLUTE ERROR: {mean_absolute_error(y_test, pred)}')
    print(f'MEAN SQUARED ERROR: {mean_squared_error(y_test, pred)}')
    print(f'ROOT MEAN SQUARED ERROR: {np.sqrt(mean_squared_error(y_test, pred))}')
    print(f'R2 SCORE: {r2_score(y_test, pred)}')

df = pd.get_dummies(df)

X = df.drop('Value', axis=1)
y = df['Value']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

"""#### Linear Regression"""

lin_model = LinearRegression()
lin_model.fit(X_train, y_train)

evaluate(lin_model, X_train, y_train, X_test, y_test)

"""#### Random Forest Regressor"""

rf_model = RandomForestRegressor(n_jobs=-1)
rf_model.fit(X_train, y_train)

evaluate(rf_model, X_train, y_train, X_test, y_test)

"""#### XGBoost Regressor"""

xgb_model = XGBRegressor(n_jobs=-1)
xgb_model.fit(X_train, y_train)

evaluate(xgb_model, X_train, y_train, X_test, y_test)

"""XGB Regressor is found to be the best Model.

### Prediction
"""

test.drop('Value', axis=1, inplace=True)

test['Month'] = test['Month'].apply(lambda x: int(x[::-1][0:2][::-1]))

test = pd.get_dummies(test)

test

predictions = xgb_model.predict(test)

predictions

def predictOutput(inputs):
    print(inputs)
    # temp = pd.DataFrame([[2021,1,1,0,0,0,1,0]],columns=list(test.columns),index=[0])
    temp = pd.DataFrame([inputs],columns=list(test.columns),index=[0])
    return jsonify({
        "predictions":float(xgb_model.predict(temp)),
    })

